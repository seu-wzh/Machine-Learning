# 决策树的一般算法
样本集
$$
D = \{ (\boldsymbol{x}_{1},\ y_{1}),\ \cdots,\ (\boldsymbol{x}_{n},\ y_{n}) \}
$$
样本属性集
$$
A = \{ a_{1},\ a_{2},\ \cdots,\ a_{n} \}
$$
如果样本集中样本类别均为$\omega$，将根节点标记为类别是$\omega$的叶节点，算法结束

如果属性集为空或样本在属性集上的取值相同，将根节点标记为类别是类别众数的叶节点，算法结束

在样本属性集中选取一个最优的属性$\hat{a}$，根据$\hat{a}$的取值划分样本集到各个子节点上

如果某个子节点上没有划分到样本，将该节点标记为类别是类别众数的叶节点

对于划分到样本子集$D_{v}$的子节点，去除属性$\hat{a}$后重复以上的算法建立子树，算法结束

## 属性选取

随着决策树的生长某一节点上的样本集的分布应当越来越集中于某一类

引入不纯度来衡量样本集在类别上的不集中程度，目前流行的不纯度定义有
- **熵不纯度**
$$
i(N) = -\sum_{i} p(\omega_{i}) \log_{2} p(\omega_{i})
$$
- **$\mathrm{Gini}$指数**
$$
i(N) = \sum_{i \ne j} p(\omega_{i}) p(\omega_{j}) = 1 - \sum_{i} p^{2}(\omega_{i})
$$

从另一角度考虑，$\mathrm{Gini}$指数代表着将任一样本的类别选做类别标记时产生的误差率
$$
\begin{align*}
    p(error) &= \mathcal{E} p(error \mid \omega_{i}) = \sum_{i} p(error \mid \omega_{i}) p(\omega_{i}) \\ \\
    &= \sum_{i} (1 - p(\omega_{i})) p(\omega_{i}) = 1 - \sum_{i} p^{2}(\omega_{i})
\end{align*}
$$
- **最小误分类概率**
$$
i(N) = 1 - \max_{i} p(\omega_{i})
$$

代表选取样本集中类别概率最大的类别作为类别标记时产生的误差率

选取一个属性划分样本集后的子节点不纯度期望为
$$
\mathcal{E}i(N_{k}) = \sum_{k = 1}^{B} p_{k} i(N_{k})
$$
其中$B$为节点分支数目，$p_{k}$代表样本分到该分支上的概率，即**条件熵**

多重分支下的**信息增益**
$$
\Delta i(s) = i(N) - \mathcal{E} i(N_{k}) = i(N) - \sum_{k = 1}^{B} p_{k} i(N_{k})
$$
考虑到分支数量带来的影响，对信息增益进行归一化得到**信息增益率**
$$
\Delta i_{B}(s) = \Delta i(s) \bigg/ -\sum_{k = 1}^{B} p_{k} \log_{2} p_{k}
$$
归一化的目的是为了规避分支数目带来的影响，例如将样本集的每个样本都划分到一个子节点上，这样所有的子节点的不纯度均为0，考虑到模型的泛化能力，这并不是一个很好的选择

在生成决策树时选择信息增益最大的属性进行分支

## 剪枝

为了降低模型对数据集的过拟合，提升泛化性能，可以去掉一些分支来降低过拟合的风险

### 预剪枝

为了比较节点分支前和分支后的模型泛化性能，将节点按类别众数标为叶节点在验证集上计算得出节点准确率。按照信息增益准则分支后采取相同的操作，再次在验证集上计算分支准确率，如果准确率没有得到提升则停止分支

预剪枝本质上是基于贪心的准则禁止分支的展开，在降低过拟合风险的同时降低了时间开销。但提高了模型欠拟合的风险

### 后剪枝

在决策树完全生成后，后序遍历决策树的每个分支节点，判断在取消节点分支后模型在验证集上的准确率有无提升，如果有则取消分支，将节点标记为类别众数的叶节点

后剪枝相较于预剪枝可以保留更多的分支，欠拟合风险较小，同时泛化性能往往优于预剪枝决策树。但后剪枝基于完全展开的决策树，不仅没有降低训练时间开销，反而增加了后序遍历和检查的时间开销

## 连续值处理

通过二分法将连续属性离散化，选择一个连续值将样本集划分为两部分

为了选取最合适的划分标准，将样本集在该连续特征上的$m$个不同的取值进行升序排序
$$
\{ a^{1},\ a^{2},\ \cdots,\ a^{m} \}
$$
分别将每个小区间$(a^{i},\ a^{i + 1})$的中点作为划分标准并计算样本集划分得到的信息增益，选取最大的信息增益对应的值作为划分标准

## 缺失值处理

缺失值下分支信息增益的计算
$$
\Delta i(s) = \rho \Delta i(\tilde{s}) = \rho \left[ i(\tilde{N}) - \sum_{k = 1}^{B} \tilde{p}_{k} i(\tilde{N}_{k}) \right]
$$
其中$\tilde{N}$为属性$a$下去除缺失值的样本集，$\rho$为完整值所占的比例

对于在属性$a$上缺失的样本可以将其按分支概率划分到不同的分支上，按最终查询到的所有的叶节点概率加权即可